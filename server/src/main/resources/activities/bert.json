{
    "title": "Training BERT, a natural language processing model, using 64 GPUs for around 80 hours",
    "consumption_in_wh": 1510000,
    "source": "https://arxiv.org/abs/1906.02243"
}
